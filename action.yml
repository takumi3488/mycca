name: 'Claude Code with S3 Backup'
description: 'Run Claude Code Action and backup projects to S3 or S3-compatible storage (MinIO, etc.)'
inputs:
  claude-code-oauth-token:
    description: 'Claude Code OAuth token'
    required: true
  aws-access-key-id:
    description: 'AWS Access Key ID'
    required: true
  aws-secret-access-key:
    description: 'AWS Secret Access Key'
    required: true
  aws-region:
    description: 'AWS Region (or region for S3-compatible storage)'
    required: false
    default: 'us-east-1'
  s3-endpoint-url:
    description: 'S3 endpoint URL (for MinIO or other S3-compatible storage)'
    required: false
  s3-force-path-style:
    description: 'Force path-style addressing (required for MinIO and some S3-compatible storage)'
    required: false
    default: 'false'
  s3-bucket:
    description: 'S3 Bucket name'
    required: true
  additional-permissions:
    description: 'Additional permissions for Claude Code'
    required: false
    default: |
      actions: read

runs:
  using: 'composite'
  steps:
    - name: Run Claude Code
      id: claude
      uses: anthropics/claude-code-action@beta
      with:
        claude_code_oauth_token: ${{ inputs.claude-code-oauth-token }}
        additional_permissions: ${{ inputs.additional-permissions || 'actions: read' }}
        model: "claude-opus-4-1-20250805"

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ inputs.aws-access-key-id }}
        aws-secret-access-key: ${{ inputs.aws-secret-access-key }}
        aws-region: ${{ inputs.aws-region || 'us-east-1' }}

    - name: Compress and upload Claude projects to S3
      shell: bash
      run: |
        CLAUDE_DIR="$HOME/.claude/projects"
        TIMESTAMP=$(date +%Y%m%d_%H%M%S)
        RUN_ID="${{ github.run_id }}"
        REPO_NAME="${{ github.repository }}"
        SAFE_REPO_NAME=$(echo "$REPO_NAME" | tr '/' '_')
        
        # Create archive filename
        ARCHIVE_NAME="claude_projects_${SAFE_REPO_NAME}_${RUN_ID}_${TIMESTAMP}.tar.gz"
        TEMP_ARCHIVE="/tmp/${ARCHIVE_NAME}"
        
        # Check if Claude projects directory exists
        if [ -d "$CLAUDE_DIR" ]; then
          echo "üì¶ Compressing Claude projects directory..."
          tar -czf "$TEMP_ARCHIVE" -C "$HOME/.claude" projects/
          
          # Calculate archive size
          ARCHIVE_SIZE=$(du -h "$TEMP_ARCHIVE" | cut -f1)
          echo "‚úÖ Archive created: ${ARCHIVE_NAME} (${ARCHIVE_SIZE})"
          
          # Upload to S3 or S3-compatible storage
          S3_PATH="s3://${{ inputs.s3-bucket }}/${ARCHIVE_NAME}"
          echo "‚òÅÔ∏è Uploading to S3-compatible storage: ${S3_PATH}"
          
          # Set S3 options for S3-compatible storage
          S3_ARGS=""
          if [ -n "${{ inputs.s3-endpoint-url }}" ]; then
            S3_ARGS="$S3_ARGS --endpoint-url ${{ inputs.s3-endpoint-url }}"
            echo "üîó Using custom endpoint: ${{ inputs.s3-endpoint-url }}"
          fi
          
          if [ "${{ inputs.s3-force-path-style || 'false' }}" = "true" ]; then
            export AWS_S3_ADDRESSING_STYLE=path
            echo "üõ£Ô∏è Using path-style addressing"
          fi
          
          aws s3 cp "$TEMP_ARCHIVE" "$S3_PATH" $S3_ARGS \
            --metadata "github-repo=${REPO_NAME},github-run-id=${RUN_ID},github-actor=${{ github.actor }},github-event=${{ github.event_name }}"
          
          if [ $? -eq 0 ]; then
            echo "‚úÖ Successfully uploaded to S3"
            echo "üìç S3 Location: ${S3_PATH}"
            
            # Output S3 location for use in other steps
            echo "s3-location=${S3_PATH}" >> $GITHUB_OUTPUT
            echo "archive-name=${ARCHIVE_NAME}" >> $GITHUB_OUTPUT
            
            # Clean up temporary file
            rm -f "$TEMP_ARCHIVE"
          else
            echo "‚ùå Failed to upload to S3"
            exit 1
          fi
        else
          echo "‚ö†Ô∏è Claude projects directory not found at: $CLAUDE_DIR"
          echo "Skipping upload..."
        fi
